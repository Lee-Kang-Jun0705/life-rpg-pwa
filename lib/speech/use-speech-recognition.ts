import { useState, useEffect, useCallback, useRef } from 'react'
import {
  SpeechRecognitionService,
  CustomSpeechRecognitionResult,
  SpeechRecognitionError,
  SpeechRecognitionStatus,
  SpeechRecognitionConfig,
  SpeechRecognitionUtils,
  KOREAN_COMMAND_GRAMMARS
} from './speech-recognition'

export interface UseSpeechRecognitionOptions extends SpeechRecognitionConfig {
  onResult?: (result: CustomSpeechRecognitionResult) => void
  onError?: (error: SpeechRecognitionError) => void
  onStatusChange?: (status: SpeechRecognitionStatus) => void
  autoStop?: boolean // ìë™ ì¢…ë£Œ ì—¬ë¶€
  timeout?: number // íƒ€ì„ì•„ì›ƒ (ms)
  customDictionary?: Map<string, string> // ì»¤ìŠ¤í…€ ë‹¨ì–´ ì‚¬ì „
}

export interface UseSpeechRecognitionReturn {
  // ìƒíƒœ
  isSupported: boolean
  isListening: boolean
  status: SpeechRecognitionStatus
  transcript: string
  confidence: number
  error: SpeechRecognitionError | null

  // ì œì–´ í•¨ìˆ˜
  start: () => void
  stop: () => void
  toggle: () => void
  reset: () => void

  // ì„¤ì • í•¨ìˆ˜
  setLanguage: (lang: string) => void
  setContinuous: (continuous: boolean) => void
}

export function useSpeechRecognition(
  options: UseSpeechRecognitionOptions = {}
): UseSpeechRecognitionReturn {
  const serviceRef = useRef<SpeechRecognitionService | null>(null)
  const timeoutRef = useRef<NodeJS.Timeout | null>(null)
  
  // optionsë¥¼ refë¡œ ê´€ë¦¬í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
  const optionsRef = useRef(options)
  optionsRef.current = options

  const [isSupported] = useState(() => SpeechRecognitionService.isSupported())
  const [isListening, setIsListening] = useState(false)
  const [status, setStatus] = useState<SpeechRecognitionStatus>('idle')
  const [transcript, setTranscript] = useState('')
  const [confidence, setConfidence] = useState(0)
  const [error, setError] = useState<SpeechRecognitionError | null>(null)

  // ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
  useEffect(() => {
    if (!isSupported) {
      setStatus('unsupported')
      return
    }

    const config: SpeechRecognitionConfig = {
      lang: optionsRef.current.lang || 'ko-KR',
      continuous: optionsRef.current.continuous ?? false,
      interimResults: optionsRef.current.interimResults ?? true,
      maxAlternatives: optionsRef.current.maxAlternatives || 3,
      grammars: optionsRef.current.grammars || KOREAN_COMMAND_GRAMMARS
    }

    const service = new SpeechRecognitionService(config)
    serviceRef.current = service

    // ê²°ê³¼ ì²˜ë¦¬
    service.onResult((result) => {
      console.log('ğŸ™ï¸ useSpeechRecognition: onResult ì½œë°± í˜¸ì¶œë¨', {
        originalTranscript: result.transcript,
        isFinal: result.isFinal,
        confidence: result.confidence
      })

      let processedTranscript = result.transcript

      // ì»¤ìŠ¤í…€ ì‚¬ì „ ì ìš©
      if (optionsRef.current.customDictionary) {
        processedTranscript = SpeechRecognitionUtils.applyCustomDictionary(
          processedTranscript,
          optionsRef.current.customDictionary
        )
      }

      // í…ìŠ¤íŠ¸ ì •ê·œí™”
      processedTranscript = SpeechRecognitionUtils.normalizeTranscript(processedTranscript)

      console.log('ğŸ“ useSpeechRecognition: ì²˜ë¦¬ëœ transcript', {
        processedTranscript,
        originalLength: result.transcript.length,
        processedLength: processedTranscript.length
      })

      setTranscript(processedTranscript)
      setConfidence(result.confidence)
      setError(null)

      optionsRef.current.onResult?.(result)

      // ìë™ ì¢…ë£Œ (ìµœì¢… ê²°ê³¼ì¼ ë•Œ)
      if (optionsRef.current.autoStop && result.isFinal) {
        console.log('ğŸ›‘ useSpeechRecognition: ìë™ ì¢…ë£Œ (ìµœì¢… ê²°ê³¼)')
        serviceRef.current?.stop()
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current)
          timeoutRef.current = null
        }
      }
    })

    // ì—ëŸ¬ ì²˜ë¦¬
    service.onError((err) => {
      setError(err)
      setIsListening(false)
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current)
        timeoutRef.current = null
      }
      optionsRef.current.onError?.(err)
    })

    // ìƒíƒœ ë³€ê²½ ì²˜ë¦¬
    service.onStatusChange((newStatus) => {
      setStatus(newStatus)
      setIsListening(newStatus === 'listening' || newStatus === 'processing')
      optionsRef.current.onStatusChange?.(newStatus)
    })

    return () => {
      service.destroy()
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current)
        timeoutRef.current = null
      }
    }
  }, [isSupported]) // optionsë¥¼ ì˜ì¡´ì„±ì—ì„œ ì œê±°

  // íƒ€ì„ì•„ì›ƒ ì •ë¦¬
  const clearListeningTimeout = useCallback(() => {
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current)
      timeoutRef.current = null
    }
  }, [])

  // ìŒì„± ì¸ì‹ ì¤‘ì§€
  const stop = useCallback(() => {
    if (!serviceRef.current) {
      return
    }

    serviceRef.current.stop()
    clearListeningTimeout()
  }, [clearListeningTimeout])

  // ìŒì„± ì¸ì‹ ì‹œì‘
  const start = useCallback(() => {
    if (!serviceRef.current || isListening || !isSupported) {
      return
    }

    setError(null)
    serviceRef.current.start()

    // íƒ€ì„ì•„ì›ƒ ì„¤ì •
    if (optionsRef.current.timeout) {
      timeoutRef.current = setTimeout(() => {
        stop()
        setError({
          name: 'SpeechRecognitionError',
          code: 'TIMEOUT',
          message: 'ìŒì„± ì¸ì‹ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.'
        })
      }, optionsRef.current.timeout)
    }
  }, [isListening, isSupported, stop])

  // í† ê¸€
  const toggle = useCallback(() => {
    if (isListening) {
      stop()
    } else {
      start()
    }
  }, [isListening, start, stop])

  // ë¦¬ì…‹
  const reset = useCallback(() => {
    stop()
    setTranscript('')
    setConfidence(0)
    setError(null)
    setStatus('idle')
  }, [stop])

  // ì–¸ì–´ ì„¤ì •
  const setLanguage = useCallback((lang: string) => {
    serviceRef.current?.setLanguage(lang)
  }, [])

  // ì—°ì† ëª¨ë“œ ì„¤ì •
  const setContinuous = useCallback((continuous: boolean) => {
    serviceRef.current?.setContinuous(continuous)
  }, [])

  return {
    // ìƒíƒœ
    isSupported,
    isListening,
    status,
    transcript,
    confidence,
    error,

    // ì œì–´ í•¨ìˆ˜
    start,
    stop,
    toggle,
    reset,

    // ì„¤ì • í•¨ìˆ˜
    setLanguage,
    setContinuous
  }
}

/**
 * í™œë™ ê¸°ë¡ìš© ìŒì„± ì¸ì‹ í›…
 */
export function useActivitySpeechRecognition() {
  const [activity, setActivity] = useState<{
    type: string | null
    description: string
  }>({ type: null, description: '' })

  const customDictionary = new Map([
    // ìš´ë™ ê´€ë ¨
    ['ëŸ°ë‹', 'ë‹¬ë¦¬ê¸°'],
    ['ì¡°ê¹…', 'ë‹¬ë¦¬ê¸°'],
    ['ì›Œí‚¹', 'ê±·ê¸°'],
    ['ì‚°ì±…', 'ê±·ê¸°'],
    ['ì§', 'í—¬ìŠ¤'],
    ['ì›¨ì´íŠ¸', 'í—¬ìŠ¤'],

    // í•™ìŠµ ê´€ë ¨
    ['ìŠ¤í„°ë””', 'ê³µë¶€'],
    ['ë¦¬ë”©', 'ë…ì„œ'],
    ['ë¶', 'ë…ì„œ'],

    // ê´€ê³„ ê´€ë ¨
    ['ë¯¸íŒ…', 'ë§Œë‚¨'],
    ['ì¹œêµ¬ë‘', 'ì¹œêµ¬ì™€'],

    // ì„±ì·¨ ê´€ë ¨
    ['ëëƒˆ', 'ì™„ë£Œí–ˆ'],
    ['ì„±ê³µí–ˆ', 'ë‹¬ì„±í–ˆ']
  ])

  const speech = useSpeechRecognition({
    lang: 'ko-KR',
    continuous: false,
    interimResults: true,
    autoStop: true,
    timeout: 30000, // 30ì´ˆ
    customDictionary,
    onResult: (result) => {
      console.log('ğŸ¯ useActivitySpeechRecognition: onResult í˜¸ì¶œë¨', {
        transcript: result.transcript,
        isFinal: result.isFinal
      })
      
      if (result.isFinal) {
        const type = SpeechRecognitionUtils.extractActivityType(result.transcript)
        setActivity({
          type,
          description: result.transcript
        })
      }
    }
  })

  const resetActivity = useCallback(() => {
    setActivity({ type: null, description: '' })
    speech.reset()
  }, [speech])

  return {
    ...speech,
    activity,
    resetActivity,
    // transcriptë¥¼ activity.descriptionìœ¼ë¡œë„ ë…¸ì¶œ
    transcript: activity.description || speech.transcript
  }
}
