import { test, expect } from '@playwright/test'

test.describe('ìŒì„± ì…ë ¥ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸', () => {
  test('ìŒì„± ì¸ì‹ ì „ì²´ í”Œë¡œìš° ë””ë²„ê·¸', async ({ page }) => {
    // ëª¨ë“  ì½˜ì†” ë¡œê·¸ ìˆ˜ì§‘
    const logs: string[] = []
    page.on('console', msg => {
      const text = msg.text()
      logs.push(`[${msg.type()}] ${text}`)
      // ìŒì„± ê´€ë ¨ ë¡œê·¸ë§Œ ì¶œë ¥
      if (text.includes('Speech Recognition') || 
          text.includes('EnhancedVoiceInput') || 
          text.includes('useSpeechRecognition') ||
          text.includes('ğŸ¤') || 
          text.includes('ğŸ™ï¸') || 
          text.includes('ğŸ“')) {
        console.log(`[${new Date().toISOString()}] ${text}`)
      }
    })

    // í˜ì´ì§€ ì´ë™
    await page.goto('/dashboard')
    await page.waitForLoadState('networkidle')
    await page.waitForTimeout(2000)

    console.log('\n=== Web Speech API ì§€ì› í™•ì¸ ===')
    const apiSupport = await page.evaluate(() => {
      const hasWebkit = 'webkitSpeechRecognition' in window
      const hasStandard = 'SpeechRecognition' in window
      
      // ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
      let canCreate = false
      try {
        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition
        if (SpeechRecognition) {
          const recognition = new SpeechRecognition()
          canCreate = true
        }
      } catch (e) {
        console.error('SpeechRecognition ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨:', e)
      }

      return {
        hasWebkit,
        hasStandard,
        canCreate,
        userAgent: navigator.userAgent
      }
    })
    console.log('API ì§€ì› ìƒíƒœ:', apiSupport)

    console.log('\n=== ìŒì„± ë²„íŠ¼ í´ë¦­ ===')
    const voiceButton = page.locator('button[aria-label*="ìŒì„±"]')
    await expect(voiceButton).toBeVisible()
    await voiceButton.click()

    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì²˜ë¦¬
    page.on('dialog', async dialog => {
      console.log('Dialog íƒ€ì…:', dialog.type())
      console.log('Dialog ë©”ì‹œì§€:', dialog.message())
      await dialog.accept()
    })

    // ê¶Œí•œ ìš”ì²­ ëŒ€ê¸°
    await page.waitForTimeout(1000)

    console.log('\n=== ìŠ¤íƒ¯ ì„ íƒ ===')
    // ê±´ê°• ìŠ¤íƒ¯ ì„ íƒ
    const healthOption = page.locator('button').filter({ 
      has: page.locator('text=ğŸ’ª') 
    }).filter({ 
      has: page.locator('text=ê±´ê°•') 
    })
    
    if (await healthOption.isVisible()) {
      await healthOption.click()
      console.log('ê±´ê°• ìŠ¤íƒ¯ ì„ íƒë¨')
    } else {
      console.log('ìŠ¤íƒ¯ ì„ íƒ ëª¨ë‹¬ì´ í‘œì‹œë˜ì§€ ì•ŠìŒ')
    }

    // ìŒì„± ì¸ì‹ ì‹œì‘ ëŒ€ê¸°
    await page.waitForTimeout(3000)

    console.log('\n=== í”„ë¡œê·¸ë˜ë° ë°©ì‹ ìŒì„± ì…ë ¥ í…ŒìŠ¤íŠ¸ ===')
    const testResult = await page.evaluate(async () => {
      // ì§ì ‘ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸
      const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition
      if (!SpeechRecognition) {
        return { error: 'SpeechRecognition API ì—†ìŒ' }
      }

      const recognition = new SpeechRecognition()
      recognition.lang = 'ko-KR'
      recognition.continuous = false
      recognition.interimResults = true

      const results: any[] = []
      
      return new Promise((resolve) => {
        recognition.onstart = () => {
          console.log('ğŸ¤ í…ŒìŠ¤íŠ¸: ìŒì„± ì¸ì‹ ì‹œì‘')
          results.push({ event: 'start', time: Date.now() })
        }

        recognition.onresult = (event: any) => {
          console.log('ğŸ™ï¸ í…ŒìŠ¤íŠ¸: ê²°ê³¼ ë°›ìŒ', event.results)
          const result = {
            event: 'result',
            time: Date.now(),
            results: Array.from(event.results).map((r: any) => ({
              isFinal: r.isFinal,
              transcript: r[0]?.transcript
            }))
          }
          results.push(result)
        }

        recognition.onerror = (event: any) => {
          console.error('âŒ í…ŒìŠ¤íŠ¸: ì—ëŸ¬', event.error)
          results.push({ 
            event: 'error', 
            error: event.error,
            message: event.message,
            time: Date.now() 
          })
          resolve({ results })
        }

        recognition.onend = () => {
          console.log('ğŸ›‘ í…ŒìŠ¤íŠ¸: ìŒì„± ì¸ì‹ ì¢…ë£Œ')
          results.push({ event: 'end', time: Date.now() })
          resolve({ results })
        }

        try {
          recognition.start()
          // 5ì´ˆ í›„ ìë™ ì¢…ë£Œ
          setTimeout(() => {
            try {
              recognition.stop()
            } catch (e) {
              console.log('ì´ë¯¸ ì¢…ë£Œë¨')
            }
          }, 5000)
        } catch (e) {
          resolve({ error: 'ì‹œì‘ ì‹¤íŒ¨', details: e })
        }
      })
    })

    console.log('\n=== ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===')
    console.log(JSON.stringify(testResult, null, 2))

    // ë¡œê·¸ ë¶„ì„
    console.log('\n=== ìˆ˜ì§‘ëœ ì¤‘ìš” ë¡œê·¸ ===')
    const importantLogs = logs.filter(log => 
      log.includes('Speech Recognition') || 
      log.includes('transcript') ||
      log.includes('error') ||
      log.includes('ë§ˆì´í¬')
    )
    importantLogs.forEach(log => console.log(log))

    // ìŠ¤í¬ë¦°ìƒ·
    await page.screenshot({ 
      path: 'voice-debug-result.png', 
      fullPage: true 
    })

    // ìµœì¢… ìƒíƒœ í™•ì¸
    const finalState = await page.evaluate(() => {
      return {
        hasTestVoiceInput: typeof (window as any).testVoiceInput === 'function',
        localStorage: { ...localStorage },
        indexedDBDatabases: Array.from(indexedDB.databases ? indexedDB.databases() : [])
      }
    })

    console.log('\n=== ìµœì¢… ìƒíƒœ ===')
    console.log('testVoiceInput ì¡´ì¬:', finalState.hasTestVoiceInput)
  })

  test('ë§ˆì´í¬ ê¶Œí•œ ëª…ì‹œì  í…ŒìŠ¤íŠ¸', async ({ page, context }) => {
    // ê¶Œí•œ ì„¤ì •
    await context.grantPermissions(['microphone'])

    await page.goto('/dashboard')
    await page.waitForLoadState('networkidle')

    const permissionStatus = await page.evaluate(async () => {
      try {
        const result = await navigator.permissions.query({ name: 'microphone' as PermissionName })
        return result.state
      } catch (e) {
        return 'error: ' + e
      }
    })

    console.log('ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ:', permissionStatus)

    // MediaDevices API í…ŒìŠ¤íŠ¸
    const mediaTest = await page.evaluate(async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        const tracks = stream.getTracks()
        const info = tracks.map(track => ({
          kind: track.kind,
          label: track.label,
          enabled: track.enabled,
          readyState: track.readyState
        }))
        tracks.forEach(track => track.stop())
        return { success: true, tracks: info }
      } catch (e: any) {
        return { success: false, error: e.name, message: e.message }
      }
    })

    console.log('MediaDevices í…ŒìŠ¤íŠ¸:', mediaTest)
  })
})